{
  "swe_bench_verified_ranking": {
    "last_updated": "2026-01-28",
    "benchmark_info": {
      "name": "SWE-bench Verified",
      "description": "Human-validated subset of SWE-bench with 500 tasks",
      "total_tasks": 500
    },
    "ranking": [
      {
        "rank": 1,
        "model_name": "Claude Opus 4.5",
        "score": 80.9,
        "organization": "Anthropic",
        "notes": "Released November 2025, first model to score over 80% on SWE-bench Verified, best coding model in the world",
        "computational_cost": "High",
        "api_cost_input": "$5.00/1M tokens",
        "api_cost_output": "$25.00/1M tokens",
        "additional_results": {
          "context_window": "200K tokens",
          "output_limit": "64K tokens",
          "knowledge_cutoff": "March 2025"
        },
        "additional_features": {
          "effort_parameter": "Adjustable reasoning depth",
          "token_efficiency": "76% fewer output tokens at medium effort",
          "swe_bench_multilingual": "Leading across 7 of 8 programming languages",
          "aider_polyglot": "10.6% improvement over Sonnet 4.5",
          "vending_bench": "29% higher performance than Sonnet 4.5"
        },
        "additional_results": {
          "swe_bench_pro": "45.9%"
        }
      },
      {
        "rank": 2,
        "model_name": "GPT-5.2 Thinking",
        "score": 80.0,
        "organization": "OpenAI",
        "notes": "Released December 11, 2025, advanced reasoning model with extended thinking capabilities",
        "computational_cost": "Very High",
        "api_cost_input": "$1.75/1M tokens",
        "api_cost_output": "$14.00/1M tokens",
        "additional_features": {
          "cached_input": "$0.175/1M tokens (90% discount)",
          "context_window": "400K tokens",
          "max_output_tokens": "128K tokens",
          "variants": [
            "Instant",
            "Thinking",
            "Pro"
          ]
        },
        "additional_results": {
          "swe_bench_pro": "55.6% (new SOTA)",
          "arc_agi": "91.4%",
          "gdpval": "70.9%"
        }
      },
      {
        "rank": 3,
        "model_name": "Claude Sonnet 4.5",
        "score": 77.2,
        "organization": "Anthropic",
        "notes": "Released September 2025, best coding model in the world, 30+ hour focus",
        "computational_cost": "Medium",
        "api_cost_input": "$3.00/1M tokens (<200K), $6.00/1M tokens (>200K)",
        "api_cost_output": "$15.00/1M tokens (<200K), $22.50/1M tokens (>200K)",
        "additional_results": {
          "swe_bench_verified_parallel": "82.0%",
          "agentic_terminal_coding": "50.0%",
          "context_window": "200K+",
          "swe_bench_pro": "43.6%"
        }
      },
      {
        "rank": 4,
        "model_name": "Kimi K2.5",
        "score": 76.8,
        "organization": "Moonshot AI",
        "notes": "Released January 2026, strongest open-source multimodal agentic model",
        "computational_cost": "Medium",
        "api_cost_input": "$0.60/1M tokens",
        "api_cost_output": "$2.50/1M tokens",
        "additional_features": {
          "context_window": "128K tokens",
          "multimodal": true,
          "agentic_capabilities": "Up to 100 agents in swarm"
        },
        "additional_results": {
          "swe_bench_multilingual": "73.0%",
          "terminal_bench_2_0": "50.8%",
          "livecodebench_v6": "85.0%"
        }
      },
      {
        "rank": 5,
        "model_name": "GPT-5.1",
        "score": 76.3,
        "organization": "OpenAI",
        "notes": "Released November 2025, improved coding capabilities, 30% fewer tokens",
        "computational_cost": "High",
        "api_cost_input": "$1.25/1M tokens",
        "api_cost_output": "$10.00/1M tokens",
        "additional_features": {
          "variants": [
            "GPT-5.1 Instant",
            "GPT-5.1 Thinking"
          ],
          "cache_discount": "90%",
          "cache_duration": "24 hours"
        }
      },
      {
        "rank": 6,
        "model_name": "Gemini 3 Pro",
        "score": 76.2,
        "organization": "Google",
        "notes": "Released November 2025, agentic coding single attempt, 1M token context",
        "computational_cost": "High",
        "api_cost_input": "$2.00/1M tokens (<200K), $4.00/1M tokens (>200K)",
        "api_cost_output": "$12.00/1M tokens (<200K), $18.00/1M tokens (>200K)",
        "additional_results": {
          "lmarena_elo": 1501,
          "context_window": "1M tokens",
          "swe_bench_pro": "43.3%"
        }
      },
      {
        "rank": 7,
        "model_name": "GPT-5",
        "score": 74.9,
        "organization": "OpenAI",
        "notes": "Released August 2025, unified reasoning model",
        "computational_cost": "High",
        "api_cost_input": "$1.25/1M tokens",
        "api_cost_output": "$10.00/1M tokens",
        "additional_results": {
          "swe_bench_pro": "41.8%"
        }
      },
      {
        "rank": 8,
        "model_name": "MiniMax M2.1",
        "score": 74.0,
        "organization": "MiniMax",
        "notes": "Released December 23, 2025, strongest open-source model for agentic workloads",
        "computational_cost": "Medium",
        "api_cost_input": "$0.27/1M tokens",
        "api_cost_output": "$1.12/1M tokens",
        "additional_features": {
          "context_window": "196K tokens",
          "max_output_tokens": "65K tokens",
          "architecture": "Sparse MoE (230B total, 10B active)"
        },
        "additional_results": {
          "swe_bench_multilingual": "72.5%",
          "vibe_aggregate": "88.6",
          "swe_bench_pro": "36.8%"
        }
      },
      {
        "rank": 9,
        "model_name": "GLM-4.7",
        "score": 73.8,
        "organization": "Zhipu AI",
        "notes": "Released December 22, 2025, open-weight coding and reasoning model",
        "computational_cost": "Medium",
        "api_cost_input": "$0.60/1M tokens",
        "api_cost_output": "$2.20/1M tokens",
        "additional_features": {
          "cached_tokens": "$0.11/1M tokens",
          "improvement_over_4_6": "+5.8%"
        },
        "additional_results": {
          "swe_bench_multilingual": "66.7% (+12.9% vs GLM-4.6)",
          "livecodebench_v6": "84.9",
          "terminal_bench_2_0": "41.0% (+16.5% improvement)"
        }
      },
      {
        "rank": 10,
        "model_name": "Grok 4",
        "score": 73.5,
        "organization": "xAI",
        "notes": "Released July 2025, 256K context window",
        "computational_cost": "Very High",
        "api_cost_input": "$3.00/1M tokens",
        "api_cost_output": "$15.00/1M tokens",
        "additional_features": {
          "cached_tokens": "$0.75/1M tokens",
          "live_search": "$25.00/1K sources"
        }
      },
      {
        "rank": 11,
        "model_name": "DeepSeek 3.2 Thinking",
        "score": 73.1,
        "organization": "DeepSeek",
        "notes": "Released September 2025, V3.2-Exp with enhanced thinking capabilities, 128K context",
        "computational_cost": "Medium",
        "api_cost_input": "$0.28/1M tokens (cache miss), $0.028/1M tokens (cache hit)",
        "api_cost_output": "$0.42/1M tokens",
        "additional_features": {
          "cache_mechanism": "90% discount on cache hit",
          "context_window": "128K tokens",
          "price_reduction": "50% cost reduction from V3.1"
        },
        "additional_results": {
          "swe_bench_verified_base": "67.8% (without thinking mode)"
        }
      },
      {
        "rank": 12,
        "model_name": "Claude 4 Sonnet",
        "score": 72.7,
        "organization": "Anthropic",
        "notes": "Released May 2025, outperforms Opus on practical coding",
        "computational_cost": "Medium",
        "api_cost_input": "$3.00/1M tokens",
        "api_cost_output": "$15.00/1M tokens",
        "additional_results": {
          "swe_bench_pro": "42.7%"
        }
      },
      {
        "rank": 13,
        "model_name": "Claude 4 Opus",
        "score": 72.5,
        "organization": "Anthropic",
        "notes": "79.4% with parallel test-time compute",
        "computational_cost": "High",
        "api_cost_input": "$15.00/1M tokens",
        "api_cost_output": "$75.00/1M tokens"
      },
      {
        "rank": 14,
        "model_name": "OpenAI o3",
        "score": 71.7,
        "organization": "OpenAI",
        "notes": "Released April 16, 2025. Official result 71.7% (Dec 2024 announcement). Can use tools directly in agentic approach. 80% price reduction",
        "computational_cost": "Very High",
        "api_cost_input": "$0.40/1M tokens",
        "api_cost_output": "$1.60/1M tokens",
        "additional_features": {
          "o3_flex": "$5.00/1M input, $20.00/1M output",
          "context_window": "200K tokens",
          "prompt_caching": "75% discount for cached tokens"
        },
        "additional_results": {
          "swe_bench_verified_69_1": "69.1% (updated measurement April 2025)",
          "codeforces_elo": 2727,
          "aime_2025": "88.9%"
        }
      },
      {
        "rank": 15,
        "model_name": "Kimi K2 (Parallel Test-time Compute)",
        "score": 71.6,
        "organization": "Moonshot AI",
        "notes": "With parallel test-time compute sampling",
        "computational_cost": "High",
        "api_cost_input": "$0.15/1M tokens",
        "api_cost_output": "$2.50/1M tokens"
      },
      {
        "rank": 16,
        "model_name": "Kimi K2 Thinking",
        "score": 71.3,
        "organization": "Moonshot AI",
        "notes": "Released November 2025, open-source reasoning model with thinking capabilities",
        "computational_cost": "High",
        "api_cost_input": "$0.15/1M tokens",
        "api_cost_output": "$2.50/1M tokens",
        "additional_results": {
          "swe_bench_multilingual": "61.1%",
          "livecodebench_v6": "83.1%",
          "terminal_bench": "47.1%"
        }
      },
      {
        "rank": 17,
        "model_name": "OpenAI o3 (Low Compute)",
        "score": 70.3,
        "organization": "OpenAI",
        "notes": "Lower compute version of o3. Historical score from Dec 2024",
        "computational_cost": "High",
        "api_cost_input": "$0.40/1M tokens",
        "api_cost_output": "$1.60/1M tokens"
      },
      {
        "rank": 18,
        "model_name": "MiniMax M2",
        "score": 69.4,
        "organization": "MiniMax",
        "notes": "Released October 27, 2025, open-weight model with 230B total parameters",
        "computational_cost": "Medium",
        "api_cost_input": "$0.30/1M tokens",
        "api_cost_output": "$1.20/1M tokens",
        "additional_features": {
          "cache_hits": "$0.03/1M tokens",
          "architecture": "Sparse MoE (230B total, 10B active)",
          "cost_comparison": "8% of Claude 4.5 Sonnet cost"
        },
        "additional_results": {
          "inference_speed": "2x faster than Claude 4.5 Sonnet"
        }
      },
      {
        "rank": 19,
        "model_name": "o4-mini",
        "score": 68.1,
        "organization": "OpenAI",
        "notes": "Released April 16, 2025. Fast cost-efficient reasoning model. Can use tools directly in agentic approach",
        "computational_cost": "Low",
        "api_cost_input": "$1.10/1M tokens",
        "api_cost_output": "$4.40/1M tokens",
        "additional_features": {
          "context_window": "200K tokens",
          "max_output_tokens": "100K tokens",
          "caching_batching": "Supported"
        },
        "additional_results": {
          "aime_2025": "92.7%"
        }
      },
      {
        "rank": 20,
        "model_name": "GLM-4.6",
        "score": 68.0,
        "organization": "Zhipu AI",
        "notes": "Released September 2025, 355B parameter MoE model with enhanced coding capabilities",
        "computational_cost": "Medium",
        "api_cost_input": "$0.60/1M tokens",
        "api_cost_output": "$2.20/1M tokens",
        "additional_features": {
          "cached_tokens": "$0.11/1M tokens",
          "glm_4_6_air": "$0.20/1M input, $1.10/1M output"
        }
      },
      {
        "rank": 21,
        "model_name": "DeepSeek V3.1",
        "score": 66.0,
        "organization": "DeepSeek",
        "notes": "Released August 21, 2025. Hybrid model with think/non-think modes. Enhanced agent capabilities and tool usage",
        "computational_cost": "Medium",
        "api_cost_input": "$0.27/1M tokens (cache miss), $0.07/1M tokens (cache hit)",
        "api_cost_output": "$1.10/1M tokens",
        "additional_results": {
          "swe_bench_multilingual": "54.5%",
          "terminal_bench": "31.3%",
          "aider_benchmark": "71.6%",
          "context_length": "128K tokens"
        }
      },
      {
        "rank": 22,
        "model_name": "DeepSeek R1 (Agentic)",
        "score": 65.8,
        "organization": "DeepSeek",
        "notes": "Open source reasoning model",
        "computational_cost": "Medium",
        "api_cost_input": "$0.55/1M tokens",
        "api_cost_output": "$2.19/1M tokens"
      },
      {
        "rank": 23,
        "model_name": "Kimi K2",
        "score": 65.8,
        "organization": "Moonshot AI",
        "notes": "Open-source trillion parameter MoE model, single attempt",
        "computational_cost": "Medium",
        "api_cost_input": "$0.15/1M tokens",
        "api_cost_output": "$2.50/1M tokens",
        "additional_results": {
          "swe_bench_pro": "27.7%"
        }
      },
      {
        "rank": 24,
        "model_name": "Mini-SWE-agent",
        "score": 65.0,
        "organization": "Open Source",
        "notes": "Achieved with 100 lines of Python code",
        "computational_cost": "Low",
        "api_cost_input": "Free/Open Source",
        "api_cost_output": "Free/Open Source"
      },
      {
        "rank": 25,
        "model_name": "GLM-4.5",
        "score": 64.2,
        "organization": "Zhipu AI",
        "notes": "Chinese AI model, open-source 355B parameter MoE model",
        "computational_cost": "Medium",
        "api_cost_input": "$0.60/1M tokens",
        "api_cost_output": "$2.20/1M tokens",
        "additional_features": {
          "cached_tokens": "$0.11/1M tokens",
          "glm_4_5_air": "$0.20/1M input, $1.10/1M output"
        }
      },
      {
        "rank": 26,
        "model_name": "Gemini 2.5 Flash",
        "score": 63.8,
        "organization": "Google",
        "notes": "Thinking model with custom agent setup",
        "computational_cost": "Medium",
        "api_cost_input": "$0.30/1M tokens",
        "api_cost_output": "$2.50/1M tokens"
      },
      {
        "rank": 27,
        "model_name": "Gemini 2.5 Pro",
        "score": 63.2,
        "organization": "Google",
        "notes": "Google's reasoning model with extended thinking capabilities",
        "computational_cost": "High",
        "api_cost_input": "$1.25/1M tokens (<200K), $2.50/1M tokens (>200K)",
        "api_cost_output": "$10.00/1M tokens (<200K), $15.00/1M tokens (>200K)",
        "additional_features": {
          "batch_api_input": "$0.625/1M (<200K), $1.25/1M (>200K)",
          "batch_api_output": "$5.00/1M (<200K), $7.50/1M (>200K)",
          "free_tier": "5 RPM, 25 requests/day"
        }
      },
      {
        "rank": 28,
        "model_name": "GPT-OSS-120b",
        "score": 62.4,
        "organization": "OpenAI",
        "notes": "Open source competitive model",
        "computational_cost": "High"
      },
      {
        "rank": 29,
        "model_name": "Claude 3.7 Sonnet",
        "score": 62.3,
        "organization": "Anthropic",
        "notes": "Previous generation model with extended thinking mode",
        "computational_cost": "Medium",
        "api_cost_input": "$3.00/1M tokens",
        "api_cost_output": "$15.00/1M tokens",
        "additional_features": {
          "thinking_tokens": "Included in output pricing",
          "prompt_caching": "90% discount",
          "batch_processing": "50% discount"
        }
      },
      {
        "rank": 30,
        "model_name": "CodeStory Midwit Agent + swe-search",
        "score": 62.0,
        "organization": "CodeStory",
        "notes": "Multi-agent brute force approach",
        "computational_cost": "Very High"
      },
      {
        "rank": 31,
        "model_name": "GPT-4.1",
        "score": 54.6,
        "organization": "OpenAI",
        "notes": "OpenAI's latest general purpose model",
        "computational_cost": "High"
      },
      {
        "rank": 32,
        "model_name": "Claude 3.5 Sonnet (Latest)",
        "score": 50.8,
        "organization": "Anthropic",
        "notes": "Latest production version",
        "computational_cost": "Medium"
      },
      {
        "rank": 33,
        "model_name": "DeepSeek R1",
        "score": 49.2,
        "organization": "DeepSeek",
        "notes": "Base reasoning model without agentic scaffolding",
        "computational_cost": "Medium",
        "api_cost_input": "$0.55/1M tokens",
        "api_cost_output": "$2.19/1M tokens"
      },
      {
        "rank": 34,
        "model_name": "Claude 3.5 Sonnet (Upgraded)",
        "score": 49.0,
        "organization": "Anthropic",
        "notes": "Previous state-of-the-art",
        "computational_cost": "Medium"
      },
      {
        "rank": 35,
        "model_name": "OpenAI o1",
        "score": 48.9,
        "organization": "OpenAI",
        "notes": "First reasoning model",
        "computational_cost": "High",
        "api_cost_input": "$15.00/1M tokens",
        "api_cost_output": "$60.00/1M tokens"
      },
      {
        "rank": 36,
        "model_name": "Grok 3",
        "score": 46.8,
        "organization": "xAI",
        "notes": "Previous generation from xAI",
        "computational_cost": "High",
        "api_cost_input": "$2.00/1M tokens (est.)",
        "api_cost_output": "$8.00/1M tokens (est.)"
      },
      {
        "rank": 37,
        "model_name": "GPT-4o",
        "score": 33.2,
        "organization": "OpenAI",
        "notes": "With best performing scaffold",
        "computational_cost": "Medium",
        "api_cost_input": "$2.50/1M tokens",
        "api_cost_output": "$10.00/1M tokens"
      }
    ]
  },
  "swe_bench_full_ranking": {
    "last_updated": "2025-11-23",
    "benchmark_info": {
      "name": "SWE-bench Full",
      "description": "Complete dataset with 2,294 real-world GitHub issues",
      "total_tasks": 2294
    },
    "ranking": [
      {
        "rank": 1,
        "model_name": "Claude 3.7 Sonnet Agent",
        "score": 33.83,
        "organization": "Anthropic",
        "notes": "As of April 2025",
        "computational_cost": "Medium",
        "api_cost_input": "$3.00/1M tokens",
        "api_cost_output": "$15.00/1M tokens"
      },
      {
        "rank": 2,
        "model_name": "Top Performers (General)",
        "score": 20.0,
        "organization": "Various",
        "notes": "Approximate range for leading models as of January 2025",
        "computational_cost": "Various"
      }
    ]
  },
  "swe_bench_lite_ranking": {
    "last_updated": "2025-11-23",
    "benchmark_info": {
      "name": "SWE-bench Lite",
      "description": "Curated subset with 300 tasks for faster evaluation",
      "total_tasks": 300
    },
    "ranking": [
      {
        "rank": 1,
        "model_name": "Top Performers",
        "score": 43.0,
        "organization": "Various",
        "notes": "As of January 2025",
        "computational_cost": "Various"
      }
    ]
  },
  "swe_bench_pro_ranking": {
    "last_updated": "2026-01-28",
    "benchmark_info": {
      "name": "SWE-bench Pro",
      "description": "Enterprise-level benchmark with 1865 tasks across 41 professional repositories",
      "total_tasks": 1865,
      "public_tasks": 731,
      "contamination_resistant": true,
      "license": "GPL and strong copyleft licenses",
      "data_source": "https://scale.com/leaderboard/swe_bench_pro_public"
    },
    "ranking": [
      {
        "rank": 1,
        "model_name": "GPT-5.2 Thinking",
        "score": 55.6,
        "organization": "OpenAI",
        "notes": "SWE-bench Pro SOTA, December 2025"
      },
      {
        "rank": 2,
        "model_name": "Claude Opus 4.5",
        "score": 45.9,
        "organization": "Anthropic",
        "notes": "November 2025"
      },
      {
        "rank": 3,
        "model_name": "Claude Sonnet 4.5",
        "score": 43.6,
        "organization": "Anthropic",
        "notes": "September 2025"
      },
      {
        "rank": 4,
        "model_name": "Gemini 3 Pro",
        "score": 43.3,
        "organization": "Google",
        "notes": "November 2025"
      },
      {
        "rank": 5,
        "model_name": "Claude 4 Sonnet",
        "score": 42.7,
        "organization": "Anthropic",
        "notes": "May 2025"
      },
      {
        "rank": 6,
        "model_name": "GPT-5",
        "score": 41.8,
        "organization": "OpenAI",
        "notes": "August 2025"
      },
      {
        "rank": 7,
        "model_name": "MiniMax M2.1",
        "score": 36.8,
        "organization": "MiniMax",
        "notes": "December 2025"
      },
      {
        "rank": 8,
        "model_name": "Kimi K2",
        "score": 27.7,
        "organization": "Moonshot AI",
        "notes": "2025"
      }
    ]
  },
  "coding_performance_metrics": {
    "codeforces_elo": [
      {
        "model_name": "OpenAI o3",
        "elo_rating": 2727,
        "percentile": 99.9,
        "notes": "International Grandmaster level, top 200 competitive coders globally"
      },
      {
        "model_name": "OpenAI o1",
        "elo_rating": 1891,
        "percentile": "Not specified",
        "notes": "Previous generation for comparison"
      },
      {
        "model_name": "Qwen3-235B",
        "elo_rating": 2056,
        "percentile": 95.0
      },
      {
        "model_name": "DeepSeek R1",
        "elo_rating": 2029,
        "percentile": 96.3
      }
    ],
    "aime_scores": [
      {
        "model_name": "OpenAI o3",
        "score": 88.9,
        "year": "2025",
        "notes": "Updated score from April 2025 release"
      },
      {
        "model_name": "o4-mini",
        "score": 92.7,
        "year": "2025",
        "notes": "Surprisingly outperformed o3 on AIME 2025"
      },
      {
        "model_name": "OpenAI o3",
        "score": 96.7,
        "year": "2024",
        "notes": "Historical score from December 2024 announcement"
      },
      {
        "model_name": "Qwen3-235B",
        "score": 85.7,
        "year": "2024"
      },
      {
        "model_name": "Qwen3-235B",
        "score": 81.4,
        "year": "2025"
      }
    ]
  },
  "performance_trends": {
    "2023": {
      "swe_bench_success_rate": 4.4,
      "description": "Early AI coding capabilities"
    },
    "2024": {
      "swe_bench_success_rate": 71.7,
      "description": "OpenAI o3 announcement (Dec 2024) - massive improvement in coding capabilities"
    },
    "2025": {
      "swe_bench_success_rate": 80.9,
      "description": "Claude Opus 4.5 breaks the 80% barrier (Nov 2025), first model to score over 80%. Claude Sonnet 4.5 achieved 77.2% (Sep 2025). GPT-5.1 and Gemini 3 Pro follow at 76.3% and 76.2%"
    }
  }
}