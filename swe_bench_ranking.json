{
  "swe_bench_verified_ranking": {
    "last_updated": "2025-11-23",
    "benchmark_info": {
      "name": "SWE-bench Verified",
      "description": "Human-validated subset of SWE-bench with 500 tasks",
      "total_tasks": 500
    },
    "ranking": [
      {
        "rank": 1,
        "model_name": "Claude Sonnet 4.5",
        "score": 77.2,
        "organization": "Anthropic",
        "notes": "Released September 2025, best coding model in the world, 30+ hour focus",
        "computational_cost": "Medium",
        "api_cost_input": "$3.00/1M tokens (<200K), $6.00/1M tokens (>200K)",
        "api_cost_output": "$15.00/1M tokens (<200K), $22.50/1M tokens (>200K)",
        "additional_results": {
          "swe_bench_verified_parallel": "82.0%",
          "agentic_terminal_coding": "50.0%",
          "context_window": "200K+"
        }
      },
      {
        "rank": 2,
        "model_name": "GPT-5.1",
        "score": 76.3,
        "organization": "OpenAI",
        "notes": "Released November 2025, improved coding capabilities, 30% fewer tokens",
        "computational_cost": "High",
        "api_cost_input": "$1.25/1M tokens",
        "api_cost_output": "$10.00/1M tokens",
        "additional_features": {
          "variants": ["GPT-5.1 Instant", "GPT-5.1 Thinking"],
          "cache_discount": "90%",
          "cache_duration": "24 hours"
        }
      },
      {
        "rank": 3,
        "model_name": "Gemini 3 Pro",
        "score": 76.2,
        "organization": "Google",
        "notes": "Released November 2025, agentic coding single attempt, 1M token context",
        "computational_cost": "High",
        "api_cost_input": "$2.00/1M tokens (<200K), $4.00/1M tokens (>200K)",
        "api_cost_output": "$12.00/1M tokens (<200K), $18.00/1M tokens (>200K)",
        "additional_results": {
          "lmarena_elo": 1501,
          "context_window": "1M tokens"
        }
      },
      {
        "rank": 4,
        "model_name": "GPT-5",
        "score": 74.9,
        "organization": "OpenAI",
        "notes": "Released August 2025, unified reasoning model",
        "computational_cost": "High",
        "api_cost_input": "$1.25/1M tokens",
        "api_cost_output": "$10.00/1M tokens"
      },
      {
        "rank": 5,
        "model_name": "Grok 4",
        "score": 73.5,
        "organization": "xAI",
        "notes": "Released July 2025, 256K context window",
        "computational_cost": "Very High",
        "api_cost_input": "$3.00/1M tokens",
        "api_cost_output": "$15.00/1M tokens",
        "additional_features": {
          "cached_tokens": "$0.75/1M tokens",
          "live_search": "$25.00/1K sources"
        }
      },
      {
        "rank": 6,
        "model_name": "Claude 4 Sonnet",
        "score": 72.7,
        "organization": "Anthropic",
        "notes": "Released May 2025, outperforms Opus on practical coding",
        "computational_cost": "Medium",
        "api_cost_input": "$3.00/1M tokens",
        "api_cost_output": "$15.00/1M tokens"
      },
      {
        "rank": 7,
        "model_name": "Claude 4 Opus",
        "score": 72.5,
        "organization": "Anthropic",
        "notes": "79.4% with parallel test-time compute",
        "computational_cost": "High",
        "api_cost_input": "$15.00/1M tokens",
        "api_cost_output": "$75.00/1M tokens"
      },
      {
        "rank": 8,
        "model_name": "OpenAI o3",
        "score": 71.7,
        "organization": "OpenAI",
        "notes": "Released April 16, 2025. Official result 71.7% (Dec 2024 announcement). Can use tools directly in agentic approach. 80% price reduction",
        "computational_cost": "Very High",
        "api_cost_input": "$0.40/1M tokens",
        "api_cost_output": "$1.60/1M tokens",
        "additional_features": {
          "o3_flex": "$5.00/1M input, $20.00/1M output",
          "context_window": "200K tokens",
          "prompt_caching": "75% discount for cached tokens"
        },
        "additional_results": {
          "swe_bench_verified_69_1": "69.1% (updated measurement April 2025)",
          "codeforces_elo": 2727,
          "aime_2025": "88.9%"
        }
      },
      {
        "rank": 9,
        "model_name": "OpenAI o3 (Low Compute)",
        "score": 70.3,
        "organization": "OpenAI",
        "notes": "Lower compute version of o3. Historical score from Dec 2024",
        "computational_cost": "High",
        "api_cost_input": "$0.40/1M tokens",
        "api_cost_output": "$1.60/1M tokens"
      },
      {
        "rank": 10,
        "model_name": "Kimi K2 (Parallel Test-time Compute)",
        "score": 71.6,
        "organization": "Moonshot AI",
        "notes": "With parallel test-time compute sampling",
        "computational_cost": "High",
        "api_cost_input": "$0.15/1M tokens",
        "api_cost_output": "$2.50/1M tokens"
      },
      {
        "rank": 11,
        "model_name": "Kimi K2 Thinking",
        "score": 71.3,
        "organization": "Moonshot AI",
        "notes": "Released November 2025, open-source reasoning model with thinking capabilities",
        "computational_cost": "High",
        "api_cost_input": "$0.15/1M tokens",
        "api_cost_output": "$2.50/1M tokens",
        "additional_results": {
          "swe_bench_multilingual": "61.1%",
          "livecodebench_v6": "83.1%",
          "terminal_bench": "47.1%"
        }
      },
      {
        "rank": 12,
        "model_name": "o4-mini",
        "score": 68.1,
        "organization": "OpenAI",
        "notes": "Released April 16, 2025. Fast cost-efficient reasoning model. Can use tools directly in agentic approach",
        "computational_cost": "Low",
        "api_cost_input": "$1.10/1M tokens",
        "api_cost_output": "$4.40/1M tokens",
        "additional_features": {
          "context_window": "200K tokens",
          "max_output_tokens": "100K tokens",
          "caching_batching": "Supported"
        },
        "additional_results": {
          "aime_2025": "92.7%"
        }
      },
      {
        "rank": 13,
        "model_name": "GLM-4.6",
        "score": 68.0,
        "organization": "Zhipu AI",
        "notes": "Released September 2025, 355B parameter MoE model with enhanced coding capabilities",
        "computational_cost": "Medium",
        "api_cost_input": "$0.60/1M tokens",
        "api_cost_output": "$2.20/1M tokens",
        "additional_features": {
          "cached_tokens": "$0.11/1M tokens",
          "glm_4_6_air": "$0.20/1M input, $1.10/1M output"
        }
      },
      {
        "rank": 14,
        "model_name": "DeepSeek V3.1",
        "score": 66.0,
        "organization": "DeepSeek",
        "notes": "Released August 21, 2025. Hybrid model with think/non-think modes. Enhanced agent capabilities and tool usage",
        "computational_cost": "Medium",
        "api_cost_input": "$0.27/1M tokens (cache miss), $0.07/1M tokens (cache hit)",
        "api_cost_output": "$1.10/1M tokens",
        "additional_results": {
          "swe_bench_multilingual": "54.5%",
          "terminal_bench": "31.3%",
          "aider_benchmark": "71.6%",
          "context_length": "128K tokens"
        }
      },
      {
        "rank": 15,
        "model_name": "DeepSeek R1 (Agentic)",
        "score": 65.8,
        "organization": "DeepSeek",
        "notes": "Open source reasoning model",
        "computational_cost": "Medium",
        "api_cost_input": "$0.55/1M tokens",
        "api_cost_output": "$2.19/1M tokens"
      },
      {
        "rank": 16,
        "model_name": "Kimi K2",
        "score": 65.8,
        "organization": "Moonshot AI",
        "notes": "Open-source trillion parameter MoE model, single attempt",
        "computational_cost": "Medium",
        "api_cost_input": "$0.15/1M tokens",
        "api_cost_output": "$2.50/1M tokens"
      },
      {
        "rank": 17,
        "model_name": "Mini-SWE-agent",
        "score": 65.0,
        "organization": "Open Source",
        "notes": "Achieved with 100 lines of Python code",
        "computational_cost": "Low",
        "api_cost_input": "Free/Open Source",
        "api_cost_output": "Free/Open Source"
      },
      {
        "rank": 18,
        "model_name": "GLM-4.5",
        "score": 64.2,
        "organization": "Zhipu AI",
        "notes": "Chinese AI model, open-source 355B parameter MoE model",
        "computational_cost": "Medium",
        "api_cost_input": "$0.60/1M tokens",
        "api_cost_output": "$2.20/1M tokens",
        "additional_features": {
          "cached_tokens": "$0.11/1M tokens",
          "glm_4_5_air": "$0.20/1M input, $1.10/1M output"
        }
      },
      {
        "rank": 19,
        "model_name": "Gemini 2.5 Flash",
        "score": 63.8,
        "organization": "Google",
        "notes": "Thinking model with custom agent setup",
        "computational_cost": "Medium",
        "api_cost_input": "$0.30/1M tokens",
        "api_cost_output": "$2.50/1M tokens"
      },
      {
        "rank": 20,
        "model_name": "Gemini 2.5 Pro",
        "score": 63.2,
        "organization": "Google",
        "notes": "Google's reasoning model with extended thinking capabilities",
        "computational_cost": "High",
        "api_cost_input": "$1.25/1M tokens (<200K), $2.50/1M tokens (>200K)",
        "api_cost_output": "$10.00/1M tokens (<200K), $15.00/1M tokens (>200K)",
        "additional_features": {
          "batch_api_input": "$0.625/1M (<200K), $1.25/1M (>200K)",
          "batch_api_output": "$5.00/1M (<200K), $7.50/1M (>200K)",
          "free_tier": "5 RPM, 25 requests/day"
        }
      },
      {
        "rank": 21,
        "model_name": "Claude 3.7 Sonnet",
        "score": 62.3,
        "organization": "Anthropic",
        "notes": "Previous generation model with extended thinking mode",
        "computational_cost": "Medium",
        "api_cost_input": "$3.00/1M tokens",
        "api_cost_output": "$15.00/1M tokens",
        "additional_features": {
          "thinking_tokens": "Included in output pricing",
          "prompt_caching": "90% discount",
          "batch_processing": "50% discount"
        }
      },
      {
        "rank": 22,
        "model_name": "GPT-OSS-120b",
        "score": 62.4,
        "organization": "OpenAI",
        "notes": "Open source competitive model",
        "computational_cost": "High"
      },
      {
        "rank": 23,
        "model_name": "CodeStory Midwit Agent + swe-search",
        "score": 62.0,
        "organization": "CodeStory",
        "notes": "Multi-agent brute force approach",
        "computational_cost": "Very High"
      },
      {
        "rank": 24,
        "model_name": "GPT-4.1",
        "score": 54.6,
        "organization": "OpenAI",
        "notes": "OpenAI's latest general purpose model",
        "computational_cost": "High"
      },
      {
        "rank": 25,
        "model_name": "Claude 3.5 Sonnet (Latest)",
        "score": 50.8,
        "organization": "Anthropic",
        "notes": "Latest production version",
        "computational_cost": "Medium"
      },
      {
        "rank": 26,
        "model_name": "DeepSeek R1",
        "score": 49.2,
        "organization": "DeepSeek",
        "notes": "Base reasoning model without agentic scaffolding",
        "computational_cost": "Medium",
        "api_cost_input": "$0.55/1M tokens",
        "api_cost_output": "$2.19/1M tokens"
      },
      {
        "rank": 27,
        "model_name": "Claude 3.5 Sonnet (Upgraded)",
        "score": 49.0,
        "organization": "Anthropic",
        "notes": "Previous state-of-the-art",
        "computational_cost": "Medium"
      },
      {
        "rank": 28,
        "model_name": "OpenAI o1",
        "score": 48.9,
        "organization": "OpenAI",
        "notes": "First reasoning model",
        "computational_cost": "High",
        "api_cost_input": "$15.00/1M tokens",
        "api_cost_output": "$60.00/1M tokens"
      },
      {
        "rank": 29,
        "model_name": "Grok 3",
        "score": 46.8,
        "organization": "xAI",
        "notes": "Previous generation from xAI",
        "computational_cost": "High",
        "api_cost_input": "$2.00/1M tokens (est.)",
        "api_cost_output": "$8.00/1M tokens (est.)"
      },
      {
        "rank": 30,
        "model_name": "GPT-4o",
        "score": 33.2,
        "organization": "OpenAI",
        "notes": "With best performing scaffold",
        "computational_cost": "Medium",
        "api_cost_input": "$2.50/1M tokens",
        "api_cost_output": "$10.00/1M tokens"
      }
    ]
  },
  "swe_bench_full_ranking": {
    "last_updated": "2025-11-23",
    "benchmark_info": {
      "name": "SWE-bench Full",
      "description": "Complete dataset with 2,294 real-world GitHub issues",
      "total_tasks": 2294
    },
    "ranking": [
      {
        "rank": 1,
        "model_name": "Claude 3.7 Sonnet Agent",
        "score": 33.83,
        "organization": "Anthropic",
        "notes": "As of April 2025",
        "computational_cost": "Medium",
        "api_cost_input": "$3.00/1M tokens",
        "api_cost_output": "$15.00/1M tokens"
      },
      {
        "rank": 2,
        "model_name": "Top Performers (General)",
        "score": 20.0,
        "organization": "Various",
        "notes": "Approximate range for leading models as of January 2025",
        "computational_cost": "Various"
      }
    ]
  },
  "swe_bench_lite_ranking": {
    "last_updated": "2025-11-23",
    "benchmark_info": {
      "name": "SWE-bench Lite",
      "description": "Curated subset with 300 tasks for faster evaluation",
      "total_tasks": 300
    },
    "ranking": [
      {
        "rank": 1,
        "model_name": "Top Performers",
        "score": 43.0,
        "organization": "Various",
        "notes": "As of January 2025",
        "computational_cost": "Various"
      }
    ]
  },
  "coding_performance_metrics": {
    "codeforces_elo": [
      {
        "model_name": "OpenAI o3",
        "elo_rating": 2727,
        "percentile": 99.9,
        "notes": "International Grandmaster level, top 200 competitive coders globally"
      },
      {
        "model_name": "OpenAI o1",
        "elo_rating": 1891,
        "percentile": "Not specified",
        "notes": "Previous generation for comparison"
      },
      {
        "model_name": "Qwen3-235B",
        "elo_rating": 2056,
        "percentile": 95.0
      },
      {
        "model_name": "DeepSeek R1",
        "elo_rating": 2029,
        "percentile": 96.3
      }
    ],
    "aime_scores": [
      {
        "model_name": "OpenAI o3",
        "score": 88.9,
        "year": "2025",
        "notes": "Updated score from April 2025 release"
      },
      {
        "model_name": "o4-mini",
        "score": 92.7,
        "year": "2025",
        "notes": "Surprisingly outperformed o3 on AIME 2025"
      },
      {
        "model_name": "OpenAI o3",
        "score": 96.7,
        "year": "2024",
        "notes": "Historical score from December 2024 announcement"
      },
      {
        "model_name": "Qwen3-235B",
        "score": 85.7,
        "year": "2024"
      },
      {
        "model_name": "Qwen3-235B",
        "score": 81.4,
        "year": "2025"
      }
    ]
  },
  "performance_trends": {
    "2023": {
      "swe_bench_success_rate": 4.4,
      "description": "Early AI coding capabilities"
    },
    "2024": {
      "swe_bench_success_rate": 71.7,
      "description": "OpenAI o3 announcement (Dec 2024) - massive improvement in coding capabilities"
    },
    "2025": {
      "swe_bench_success_rate": 77.2,
      "description": "Claude Sonnet 4.5 achieves new state-of-the-art (Sep 2025). GPT-5.1 and Gemini 3 Pro follow at 76.3% and 76.2%"
    }
  }
}